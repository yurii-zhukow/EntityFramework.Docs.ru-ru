---
title: Моделирование EF Core производительности
description: Эффективное моделирование при использовании Entity Framework Core
author: roji
ms.date: 12/1/2020
uid: core/performance/modeling-for-performance
ms.openlocfilehash: 882398189cc828798c1682f849fac524d90d317f
ms.sourcegitcommit: 4798ab8d04c1fdbe6dd204d94d770fcbf309d09b
ms.translationtype: MT
ms.contentlocale: ru-RU
ms.lasthandoff: 03/11/2021
ms.locfileid: "103023865"
---
# <a name="modeling-for-performance"></a>Моделирование производительности

Во многих случаях способ моделирования может иметь более глубокое воздействие на производительность приложения. Хотя правильно нормализованная и «правильная» модель обычно является хорошей отправной точкой, в реальных приложениях некоторые из практических компромиссов могут быть длительным образом для достижения хорошей производительности. Поскольку модель очень сложно изменить после того, как приложение выполняется в рабочей среде, при создании начальной модели следует помнить о снижении производительности.

## <a name="denormalization-and-caching"></a>Денормализация и кэширование

*Денормализация* — это практика добавления избыточных данных в схему, обычно для исключения соединений при выполнении запросов. Например, для модели с блогами и записями, где каждая запись имеет рейтинг, может потребоваться частое отображение средней оценки блога. Простой подход к этому — Группировка записей по блогу и вычисление среднего значения в составе запроса. но для этого требуется дорогостоящая связь между двумя таблицами. Денормализация приведет к добавлению вычисленного среднего значения всех записей в новый столбец блога, чтобы он был немедленно доступен без присоединения или вычисления.

Приведенные выше сведения можно просмотреть в виде формы *кэширования* . статистические данные из записей кэшируются в своем блоге. и, как и при любом кэшировании, проблема заключается в том, как хранить кэшированное значение в актуальном состоянии с помощью кэшированных данных. Во многих случаях кэшированные данные могут задерживается в течение определенного бита. Например, в приведенном выше примере обычно целесообразно, чтобы средняя оценка блога не была полностью актуальной в любой момент времени. Если это так, можно выполнить повторное вычисление каждого из них, а затем; в противном случае необходимо настроить более сложную систему, чтобы поддерживать кэшированные значения в актуальном состоянии.

Ниже приведены некоторые методы денормализации и кэширования в EF Core и указываются соответствующие разделы в документации.

### <a name="stored-computed-columns"></a>Сохраненные столбцы с вычислением

Если данные для кэширования являются продуктом других столбцов в той же таблице, то [хранимый вычисляемый столбец](xref:core/modeling/generated-properties#computed-columns) может быть идеальным решением. Например, `Customer` может иметь `FirstName` `LastName` столбцы и, но может потребоваться выполнить поиск по *полному имени* клиента. Хранимый вычисляемый столбец автоматически обслуживается базой данных, который повторно вычисляет его при каждом изменении строки. можно даже определить индекс для ускорения запросов.

### <a name="update-cache-columns-when-inputs-change"></a>Обновлять столбцы кэша при изменении входных данных

Если кэшированный столбец должен ссылаться на входные данные извне строки таблицы, нельзя использовать вычисляемые столбцы. Однако по-прежнему возможно повторное вычисление столбца при изменении его входных данных. Например, можно повторно рассчитать среднюю оценку блога каждый раз при изменении, добавлении или удалении записи. Не забудьте определить точные условия, когда требуется повторное вычисление, в противном случае кэшированное значение будет выходить из синхронизации.

Один из способов сделать это — выполнить обновление самостоятельно с помощью регулярного EF Core API. `SaveChanges`[События](xref:core/logging-events-diagnostics/events) или [перехватчики](xref:core/logging-events-diagnostics/interceptors#savechanges-interception) можно использовать для автоматической проверки наличия обновлений записей, а также для выполнения повторного вычисления. Обратите внимание, что это обычно влечет за собой дополнительные обращения к базе данных, так как необходимо отправить дополнительные команды.

Для дополнительных приложений с учетом производительности можно определить триггеры базы данных, чтобы автоматически выполнять повторное вычисление в базе данных. Это экономит лишнюю базу данных, автоматически происходит в той же транзакции, что и основное обновление, и может быть проще в настройке. EF не предоставляет какой-либо конкретный API для создания или обслуживания триггеров, но вполне удобно [создать пустую миграцию и добавить определение триггера с помощью необработанного SQL](xref:core/managing-schemas/migrations/managing#arbitrary-changes-via-raw-sql).

### <a name="materialized-views"></a>материализованные представления;

Материализованные представления похожи на обычные представления, за исключением того, что их данные хранятся на диске ("материализованный"), а не рассчитываются каждый раз при запросе представления. Это средство полезно, если вы не хотите просто добавить один столбец кэша в существующую базу данных, а хотите кэшировать весь набор результатов сложных и дорогостоящих результатов запроса так же, как если бы он был обычной таблицей. Эти результаты можно запрашивать очень дешево без каких бы то ни было вычислений или соединений. В отличие от вычисленных столбцов материализованные представления не обновляются автоматически при изменении их базовых таблиц — они должны быть обновлены вручную. Если кэшированные данные могут отставать, обновление представления может выполняться через таймер. другой вариант — настроить триггеры базы данных для просмотра материализованных представлений после возникновения определенных событий базы данных.

EF в настоящее время не предоставляет какой-либо конкретный API для создания или обслуживания представлений, материализованных или иным образом; но вполне неплохо [создать пустую миграцию и добавить определение представления с помощью необработанного SQL](xref:core/managing-schemas/migrations/managing#arbitrary-changes-via-raw-sql).

## <a name="inheritance-mapping"></a>Сопоставление наследования

Перед продолжением работы с этим разделом рекомендуется прочитать [выделенную страницу по наследованию](xref:core/modeling/inheritance) .

В настоящее время EF Core поддерживает два метода сопоставления модели наследования с реляционной базой данных:

* Одна **таблица на иерархию** , в которой вся иерархия .NET классов сопоставлена с одной таблицей базы данных
* **Тип «Таблица для каждого типа** » (TPT), в котором каждый тип в иерархии .NET сопоставляется с другой таблицей в базе данных.

Выбранный способ сопоставления наследования может оказать значительное влияние на производительность приложения. рекомендуется тщательно оценить перед фиксацией в выборе.

Иногда люди выбирают TPT, поскольку по-видимому, является методом очистки; отдельная таблица для каждого типа .NET делает схему базы данных похожей на иерархию типов .NET. Кроме того, поскольку иерархия должна представлять всю иерархию в одной таблице, строки имеют *все* столбцы независимо от типа, который фактически удерживается в строке, а несвязанные столбцы всегда пусты и не используются. Помимо этого, многие считают, что эти пустые столбцы занимают значительное пространство в базе данных и могут также понизить производительность.

Тем не менее, измерение показывает, что TPT в большинстве случаев является методом подстановки с точки зрения производительности; Если все данные в подразделениях берутся из одной таблицы, TPT запросы должны соединяться вместе с несколькими таблицами, а объединения являются одним из основных источников проблем производительности в реляционных базах данных. Базы данных, как правило, хорошо работают с пустыми столбцами, а такие функции, как [SQL Server разреженные столбцы](/sql/relational-databases/tables/use-sparse-columns) , могут еще больше снизить эту нагрузку.

Конкретный пример см. в [разделе этот тест производительности](https://github.com/dotnet/EntityFramework.Docs/tree/main/samples/core/Benchmarks/Inheritance.cs) , который настраивает простую модель с иерархией типа 7. 5000 строки заполнены для каждого типа суммируя 35000 строк. тест производительности просто загружает все строки из базы данных:

| Метод |     Среднее значение |   Ошибка |  StdDev |     Gen 0 |     Gen 1 |     Gen 2 | Allocated |
|------- |---------:|--------:|--------:|----------:|----------:|----------:|----------:|
|    ПРИНЦИП | 132,3 мс | 2,29 МС | 2,03 мс | 8000,0000 | 3000,0000 | 1250,0000 |  44,49 МБ |
|    TPT | 201,3 мс | 3,32 МС | 3,10 мс | 9000,0000 | 4000,0000 |         - |  61,84 МБ |

Как можно заметить, в этом сценарии для этой ситуации гораздо эффективнее использовать подиерархию, чем TPT. Обратите внимание, что фактические результаты всегда зависят от выполняемого запроса и количества таблиц в иерархии, поэтому другие запросы могут показывать другой зазор производительности. рекомендуется использовать этот код теста производительности в качестве шаблона для тестирования других запросов.
